{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7EmviKSHhned"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets.public_api as tfds\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5i5jnPRjIW3"
      },
      "outputs": [],
      "source": [
        "d = tfds.load(name='tiny_shakespeare')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MARHn7d2lReD"
      },
      "outputs": [],
      "source": [
        "train_text = list(d['train'].as_numpy_iterator())[0]['text'].decode()\n",
        "test_text = list(d['test'].as_numpy_iterator())[0]['text'].decode()\n",
        "validation_text = list(d['validation'].as_numpy_iterator())[0]['text'].decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gdoZ8NgoFMH",
        "outputId": "fc26b629-78b7-4fa2-cdc7-d01ce2e65464"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d9KeEqLHobYl"
      },
      "outputs": [],
      "source": [
        "vocab = sorted(set(train_text))\n",
        "charToIdx = {u:i for i, u in enumerate(vocab)}\n",
        "idxToChar = {i:u for i, u in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mdUQ9b7jouvv",
        "outputId": "3622833c-9366-4050-b68a-6583252b81a7"
      },
      "outputs": [],
      "source": [
        "charToIdx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IXrwr7sso96V"
      },
      "outputs": [],
      "source": [
        "train_text_encoded = np.array([charToIdx[c] for c in train_text])\n",
        "test_text_encoded = np.array([charToIdx[c] for c in test_text])\n",
        "validation_text_encoded = np.array([charToIdx[c] for c in validation_text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ftvSIgs4sT8j"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(train_text_encoded) // (seq_length + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3FstGtNCsclh"
      },
      "outputs": [],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(train_text_encoded).batch(seq_length + 1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uoVu-1U5tApS"
      },
      "outputs": [],
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]   # all except last char\n",
        "    target_text = chunk[1:]   # all except first char\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i8TO9F2btDyj"
      },
      "outputs": [],
      "source": [
        "dataset = char_dataset.map(split_input_target).shuffle(10000).batch(64, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT9eDypRtlAr",
        "outputId": "f7f11301-1cb0-4e0b-d8b6-94f11c86c75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[59 57 58  1 40 43  6  1 47 44  1 58 46 43  1 49 47 52 45  1 51 47 57 41\n",
            " 39 56 56 63  8  0  0 19 30 17 37 10  0 20 43 56 43  1 41 53 51 43  1 58\n",
            " 46 43  1 50 53 56 42 57  1 53 44  1 14 59 41 49 47 52 45 46 39 51  1 39\n",
            " 52 42  1 16 43 56 40 63  8  0  0 14 33 15 23 21 26 19 20 13 25 10  0 19\n",
            " 53 53 42  1], shape=(100,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[57 58  1 40 43  6  1 47 44  1 58 46 43  1 49 47 52 45  1 51 47 57 41 39\n",
            " 56 56 63  8  0  0 19 30 17 37 10  0 20 43 56 43  1 41 53 51 43  1 58 46\n",
            " 43  1 50 53 56 42 57  1 53 44  1 14 59 41 49 47 52 45 46 39 51  1 39 52\n",
            " 42  1 16 43 56 40 63  8  0  0 14 33 15 23 21 26 19 20 13 25 10  0 19 53\n",
            " 53 42  1 58], shape=(100,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "  for j in i:\n",
        "    print(j[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "I7pCV2RYp8If"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size, seq_length):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
        "        LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "        Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "_ct9AdQXqA4h",
        "outputId": "4be2dbbb-b9d6-4e27-9653-1a1478a112a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = build_model(len(vocab), 128, 256, 64, seq_length)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EULyx3VxvXSo"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWCoTslgvc4l",
        "outputId": "2efc9520-84db-4192-90a6-792fd32ebea5"
      },
      "outputs": [],
      "source": [
        "model.fit(dataset, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "2EU58W-lx4fD",
        "outputId": "acddc731-074f-4d67-dbbb-d552297d68ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,705</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m8,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m394,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m65\u001b[0m)          │        \u001b[38;5;34m16,705\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,257,797</span> (4.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,257,797\u001b[0m (4.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">419,265</span> (1.60 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m419,265\u001b[0m (1.60 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">838,532</span> (3.20 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m838,532\u001b[0m (3.20 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3nfiqIggwJPI"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_string, char2idx, idx2char, num_generate=500, temperature=1.0):\n",
        "    \"\"\"\n",
        "    model: trained model\n",
        "    start_string: string prompt to start with\n",
        "    char2idx, idx2char: vocab mappings\n",
        "    num_generate: number of characters to generate\n",
        "    temperature: controls randomness (>1: more random, <1: more greedy)\n",
        "    \"\"\"\n",
        "    # Converting start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)  # shape: (1, len(start_string))\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    # # Reset model states if using stateful=True\n",
        "    # model.reset_states()\n",
        "\n",
        "    for _ in range(num_generate):\n",
        "        # predictions shape: (1, seq_length, vocab_size)\n",
        "        predictions = model(input_eval)\n",
        "        predictions = predictions[:, -1, :]  # get last timestep, shape: (1, vocab_size)\n",
        "        predictions = predictions / temperature  # adjust randomness\n",
        "        # Sample next character\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "        # Append predicted character\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "        # Use predicted_id as next input\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return start_string + ''.join(text_generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qolkYdpYwKz2",
        "outputId": "fb5ed678-d78a-49f4-e31a-5f8cccea2078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rance ta'en\n",
            "As shall with either part's agreement stand?\n",
            "\n",
            "BAPTISTA:\n",
            "Not in my house, Lucentio; for, let me go.\n",
            "\n",
            "GLOUCESTER:\n",
            "I queen now, cousin! then ever lies to beet.\n",
            "I am may both a shame is myself.\n",
            "He is yet one or so father to he\n",
            "Do the leave with suitive I see thy friends.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "Nay, take my heart be king;' as be still en pomper,\n",
            "She's oaths: I was a presence, follows to\n",
            "Which God depart: sir, you both, thou wast unto:\n",
            "An, let them go,\n",
            "And, noble hocose is to blame to fear:\n",
            "That's chas;\n",
            "And might be so and with cursen'd murder'd,\n",
            "But as so discover'd, hay thou know to\n",
            "need you\n"
          ]
        }
      ],
      "source": [
        "generated_text = generate_text(\n",
        "    model,\n",
        "    start_string=test_text[:100],\n",
        "    char2idx=charToIdx,\n",
        "    idx2char=idxToChar,\n",
        "    num_generate=500,\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fleTdlZi41Z5",
        "outputId": "7c661f4c-f235-470f-a378-1ff7e46b3fb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rance ta'en\n",
            "As shall with either part's agreement stand?\n",
            "\n",
            "BAPTISTA:\n",
            "Not in my house, Lucentio; for, you know,\n",
            "Pitchers have ears, and I have many servants:\n",
            "Besides, old Gremio is hearkening still;\n",
            "And happily we might be interrupted.\n",
            "\n",
            "TRANIO:\n",
            "Then at my lodging, an it like you:\n",
            "There doth my father lie; and there, this night,\n",
            "We'll pass the business privately and well.\n",
            "Send for your daughter by your servant here:\n",
            "My boy shall fetch the scrivener presently.\n",
            "The worst is this, that, at so slender warning,\n",
            "You are like to have a thin and slender pittance.\n",
            "\n",
            "BAPTISTA:\n",
            "It likes me well. Biondello, h\n"
          ]
        }
      ],
      "source": [
        "print(test_text[:600])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
